{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar100\n",
    "\n",
    "# Load the CIFAR-100 dataset\n",
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data(label_mode='fine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_train: (50000, 32, 32, 3)\n",
      "Shape of y_train: (50000, 1)\n",
      "Shape of x_test: (10000, 32, 32, 3)\n",
      "Shape of y_test: (10000, 1)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Explore the dataset\n",
    "print(\"Shape of x_train:\", x_train.shape)\n",
    "print(\"Shape of y_train:\", y_train.shape)\n",
    "print(\"Shape of x_test:\", x_test.shape)\n",
    "print(\"Shape of y_test:\", y_test.shape)\n",
    "\n",
    "# Display a few examples from the training set\n",
    "# Display 5 random images from the training set\n",
    "plt.figure(figsize=(10, 5))\n",
    "for i in range(5):\n",
    "    plt.subplot(1, 5, i+1)\n",
    "    plt.imshow(x_train[i])\n",
    "    plt.title(f'Label: {y_train[i][0]}')\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_train: (40000, 32, 32, 3)\n",
      "Shape of x_val: (10000, 32, 32, 3)\n",
      "Shape of y_train: (40000, 100)\n",
      "Shape of y_val: (10000, 100)\n",
      "Shape of x_test: (10000, 32, 32, 3)\n",
      "Shape of y_test: (10000, 100)\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Normalize the images to the range [0, 1]\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "# One-hot encode the labels\n",
    "y_train = to_categorical(y_train, num_classes=100)\n",
    "y_test = to_categorical(y_test, num_classes=100)\n",
    "\n",
    "# Split the training set into training and validation sets (80% train, 20% validation)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Display the shapes of the data after preprocessing\n",
    "print(\"Shape of x_train:\", x_train.shape)\n",
    "print(\"Shape of x_val:\", x_val.shape)\n",
    "print(\"Shape of y_train:\", y_train.shape)\n",
    "print(\"Shape of y_val:\", y_val.shape)\n",
    "print(\"Shape of x_test:\", x_test.shape)\n",
    "print(\"Shape of y_test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 32, 32, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 16, 16, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 8, 8, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 8, 8, 128)         73856     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 8192)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               4194816   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100)               51300     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,339,364\n",
      "Trainable params: 4,339,364\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "# Create a Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Add the first convolutional layer with 32 filters, kernel size of 3x3, ReLU activation, and padding\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(32, 32, 3)))\n",
    "\n",
    "# Add a max-pooling layer with pool size of 2x2\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Add the second convolutional layer with 64 filters\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "\n",
    "# Add another max-pooling layer\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Add the third convolutional layer with 128 filters\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "\n",
    "# Flatten the output from the convolutional layers\n",
    "model.add(Flatten())\n",
    "\n",
    "# Add a fully connected dense layer with 512 units and ReLU activation\n",
    "model.add(Dense(512, activation='relu'))\n",
    "\n",
    "# Add the output layer with 100 units (since there are 100 classes) and softmax activation\n",
    "model.add(Dense(100, activation='softmax'))\n",
    "\n",
    "# Print out the model summary to inspect the architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "# Compile the model with categorical crossentropy loss and Adam optimizer\n",
    "model.compile(optimizer=optimizers.Adam(), \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Brief explanation:\n",
    "# Loss function: categorical_crossentropy is used because we are performing multi-class classification with one-hot encoded labels.\n",
    "# Optimizer: Adam is chosen for its adaptive learning rate, which often leads to faster and more stable convergence in deep learning tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1250/1250 [==============================] - 52s 40ms/step - loss: 3.6057 - accuracy: 0.1559 - val_loss: 3.0684 - val_accuracy: 0.2562\n",
      "Epoch 2/20\n",
      "1250/1250 [==============================] - 50s 40ms/step - loss: 2.7296 - accuracy: 0.3106 - val_loss: 2.7340 - val_accuracy: 0.3207\n",
      "Epoch 3/20\n",
      "1250/1250 [==============================] - 50s 40ms/step - loss: 2.2142 - accuracy: 0.4268 - val_loss: 2.5969 - val_accuracy: 0.3492\n",
      "Epoch 4/20\n",
      "1250/1250 [==============================] - 72s 58ms/step - loss: 1.7157 - accuracy: 0.5354 - val_loss: 2.6320 - val_accuracy: 0.3685\n",
      "Epoch 5/20\n",
      "1250/1250 [==============================] - 49s 39ms/step - loss: 1.1936 - accuracy: 0.6654 - val_loss: 2.9341 - val_accuracy: 0.3635\n",
      "Epoch 6/20\n",
      "1250/1250 [==============================] - 51s 41ms/step - loss: 0.7199 - accuracy: 0.7901 - val_loss: 3.5123 - val_accuracy: 0.3559\n",
      "Epoch 7/20\n",
      "1250/1250 [==============================] - 52s 42ms/step - loss: 0.4182 - accuracy: 0.8728 - val_loss: 4.3591 - val_accuracy: 0.3376\n",
      "Epoch 8/20\n",
      "1250/1250 [==============================] - 92s 73ms/step - loss: 0.3007 - accuracy: 0.9065 - val_loss: 4.6110 - val_accuracy: 0.3418\n",
      "Epoch 9/20\n",
      "1250/1250 [==============================] - 49s 39ms/step - loss: 0.2410 - accuracy: 0.9250 - val_loss: 5.2719 - val_accuracy: 0.3329\n",
      "Epoch 10/20\n",
      "1250/1250 [==============================] - 50s 40ms/step - loss: 0.2075 - accuracy: 0.9366 - val_loss: 5.7036 - val_accuracy: 0.3369\n",
      "Epoch 11/20\n",
      "1250/1250 [==============================] - 52s 42ms/step - loss: 0.1908 - accuracy: 0.9399 - val_loss: 5.8686 - val_accuracy: 0.3234\n",
      "Epoch 12/20\n",
      "1250/1250 [==============================] - 58s 46ms/step - loss: 0.1631 - accuracy: 0.9498 - val_loss: 6.2682 - val_accuracy: 0.3350\n",
      "Epoch 13/20\n",
      "1250/1250 [==============================] - 51s 41ms/step - loss: 0.1582 - accuracy: 0.9515 - val_loss: 6.7540 - val_accuracy: 0.3266\n",
      "Epoch 14/20\n",
      "1250/1250 [==============================] - 48s 39ms/step - loss: 0.1462 - accuracy: 0.9547 - val_loss: 7.0592 - val_accuracy: 0.3324\n",
      "Epoch 15/20\n",
      "1250/1250 [==============================] - 50s 40ms/step - loss: 0.1582 - accuracy: 0.9535 - val_loss: 7.1585 - val_accuracy: 0.3346\n",
      "Epoch 16/20\n",
      "1250/1250 [==============================] - 52s 41ms/step - loss: 0.1383 - accuracy: 0.9573 - val_loss: 7.0681 - val_accuracy: 0.3242\n",
      "Epoch 17/20\n",
      "1250/1250 [==============================] - 55s 44ms/step - loss: 0.1282 - accuracy: 0.9614 - val_loss: 7.7685 - val_accuracy: 0.3275\n",
      "Epoch 18/20\n",
      "1250/1250 [==============================] - 51s 40ms/step - loss: 0.1261 - accuracy: 0.9634 - val_loss: 7.9204 - val_accuracy: 0.3291\n",
      "Epoch 19/20\n",
      "1250/1250 [==============================] - 56s 45ms/step - loss: 0.1217 - accuracy: 0.9639 - val_loss: 8.0922 - val_accuracy: 0.3239\n",
      "Epoch 20/20\n",
      "1250/1250 [==============================] - 58s 46ms/step - loss: 0.1239 - accuracy: 0.9633 - val_loss: 8.5758 - val_accuracy: 0.3308\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(x_train, y_train, \n",
    "                    epochs=20,            # Number of epochs\n",
    "                    batch_size=32,        # Batch size\n",
    "                    validation_data=(x_val, y_val))  # Use validation data for evaluation\n",
    "\n",
    "# Brief explanation:\n",
    "# Epochs: We start with 20 epochs as a common baseline. You can adjust this number based on the results after training.\n",
    "# Batch size: We choose 32, which is a commonly used batch size that balances memory and performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1250/1250 [==============================] - 65s 51ms/step - loss: 4.5384 - accuracy: 0.0293 - val_loss: 4.2263 - val_accuracy: 0.0560\n",
      "Epoch 2/20\n",
      "1250/1250 [==============================] - 63s 50ms/step - loss: 4.2300 - accuracy: 0.0572 - val_loss: 4.0887 - val_accuracy: 0.0752\n",
      "Epoch 3/20\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 4.1383 - accuracy: 0.0729 - val_loss: 4.0273 - val_accuracy: 0.0945\n",
      "Epoch 4/20\n",
      "1250/1250 [==============================] - 61s 48ms/step - loss: 4.0772 - accuracy: 0.0820 - val_loss: 3.9484 - val_accuracy: 0.1073\n",
      "Epoch 5/20\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 4.0419 - accuracy: 0.0904 - val_loss: 3.9141 - val_accuracy: 0.1133\n",
      "Epoch 6/20\n",
      "1250/1250 [==============================] - 70s 56ms/step - loss: 4.0081 - accuracy: 0.0962 - val_loss: 3.9190 - val_accuracy: 0.1146\n",
      "Epoch 7/20\n",
      "1250/1250 [==============================] - 89s 71ms/step - loss: 3.9921 - accuracy: 0.0997 - val_loss: 3.9223 - val_accuracy: 0.1137\n",
      "Epoch 8/20\n",
      "1250/1250 [==============================] - 61s 49ms/step - loss: 3.9829 - accuracy: 0.1012 - val_loss: 3.8499 - val_accuracy: 0.1235\n",
      "Epoch 9/20\n",
      "1250/1250 [==============================] - 66s 53ms/step - loss: 3.9736 - accuracy: 0.1022 - val_loss: 3.8331 - val_accuracy: 0.1293\n",
      "Epoch 10/20\n",
      "1250/1250 [==============================] - 59s 47ms/step - loss: 3.9649 - accuracy: 0.1059 - val_loss: 3.8181 - val_accuracy: 0.1367\n",
      "Epoch 11/20\n",
      "1250/1250 [==============================] - 62s 49ms/step - loss: 3.9484 - accuracy: 0.1084 - val_loss: 3.8191 - val_accuracy: 0.1356\n",
      "Epoch 12/20\n",
      "1250/1250 [==============================] - 61s 49ms/step - loss: 3.9423 - accuracy: 0.1123 - val_loss: 3.8136 - val_accuracy: 0.1327\n",
      "Epoch 13/20\n",
      "1250/1250 [==============================] - 115s 92ms/step - loss: 3.9379 - accuracy: 0.1124 - val_loss: 3.8186 - val_accuracy: 0.1427\n",
      "Epoch 14/20\n",
      "1250/1250 [==============================] - 61s 48ms/step - loss: 3.9313 - accuracy: 0.1130 - val_loss: 3.8091 - val_accuracy: 0.1397\n",
      "Epoch 15/20\n",
      "1250/1250 [==============================] - 62s 50ms/step - loss: 3.9227 - accuracy: 0.1152 - val_loss: 3.7981 - val_accuracy: 0.1405\n",
      "Epoch 16/20\n",
      "1250/1250 [==============================] - 60s 48ms/step - loss: 3.9168 - accuracy: 0.1160 - val_loss: 3.7627 - val_accuracy: 0.1463\n",
      "Epoch 17/20\n",
      "1250/1250 [==============================] - 320s 256ms/step - loss: 3.9193 - accuracy: 0.1162 - val_loss: 3.8205 - val_accuracy: 0.1363\n",
      "Epoch 18/20\n",
      "1250/1250 [==============================] - 62s 49ms/step - loss: 3.9095 - accuracy: 0.1170 - val_loss: 3.7722 - val_accuracy: 0.1449\n",
      "Epoch 19/20\n",
      "1250/1250 [==============================] - 69s 55ms/step - loss: 3.9097 - accuracy: 0.1155 - val_loss: 3.7573 - val_accuracy: 0.1490\n",
      "Epoch 20/20\n",
      "1250/1250 [==============================] - 61s 48ms/step - loss: 3.8998 - accuracy: 0.1182 - val_loss: 3.7634 - val_accuracy: 0.1549\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "from keras.regularizers import l2\n",
    "from keras.layers import Dropout\n",
    "\n",
    "# Recreate the model with Dropout and L2 regularization\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(32, 32, 3), kernel_regularizer=l2(0.01)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=l2(0.01)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=l2(0.01)),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    Dropout(0.5),  # Add Dropout\n",
    "    Dense(100, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model again\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Add EarlyStopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(x_train, y_train, epochs=20, batch_size=32, validation_data=(x_val, y_val), callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1250/1250 [==============================] - 21s 16ms/step - loss: 3.7391 - accuracy: 0.1337 - val_loss: 3.2533 - val_accuracy: 0.2132\n",
      "Epoch 2/20\n",
      "1250/1250 [==============================] - 20s 16ms/step - loss: 3.0109 - accuracy: 0.2613 - val_loss: 2.8829 - val_accuracy: 0.2925\n",
      "Epoch 3/20\n",
      "1250/1250 [==============================] - 22s 17ms/step - loss: 2.6579 - accuracy: 0.3308 - val_loss: 2.7082 - val_accuracy: 0.3268\n",
      "Epoch 4/20\n",
      "1250/1250 [==============================] - 18s 14ms/step - loss: 2.4168 - accuracy: 0.3828 - val_loss: 2.6585 - val_accuracy: 0.3380\n",
      "Epoch 5/20\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 2.2427 - accuracy: 0.4157 - val_loss: 2.6348 - val_accuracy: 0.3486\n",
      "Epoch 6/20\n",
      "1250/1250 [==============================] - 17s 13ms/step - loss: 2.0873 - accuracy: 0.4521 - val_loss: 2.6343 - val_accuracy: 0.3544\n",
      "Epoch 7/20\n",
      "1250/1250 [==============================] - 18s 15ms/step - loss: 1.9480 - accuracy: 0.4808 - val_loss: 2.6033 - val_accuracy: 0.3634\n",
      "Epoch 8/20\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 1.8167 - accuracy: 0.5084 - val_loss: 2.6710 - val_accuracy: 0.3526\n",
      "Epoch 9/20\n",
      "1250/1250 [==============================] - 17s 14ms/step - loss: 1.6906 - accuracy: 0.5395 - val_loss: 2.7130 - val_accuracy: 0.3594\n",
      "Epoch 10/20\n",
      "1250/1250 [==============================] - 22s 18ms/step - loss: 1.5879 - accuracy: 0.5656 - val_loss: 2.8051 - val_accuracy: 0.3553\n"
     ]
    }
   ],
   "source": [
    "# Simplified model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(32, 32, 3)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(100, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(x_train, y_train, epochs=20, batch_size=32, validation_data=(x_val, y_val), callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# Example of loading your dataset\n",
    "# Replace this with your dataset\n",
    "X = np.random.rand(1000, 20)  # Example feature data with 1000 samples and 20 features\n",
    "y = np.random.randint(0, 2, 1000)  # Example binary labels (0 or 1) for classification\n",
    "\n",
    "# Split the data into training, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Optionally, you can scale your features to ensure proper model performance\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Преобразуем метки в one-hot формат для обучения и валидации\n",
    "y_train_onehot = to_categorical(y_train, num_classes=2)  # Замените num_classes в зависимости от количества классов\n",
    "y_val_onehot = to_categorical(y_val, num_classes=2)\n",
    "y_test_onehot = to_categorical(y_test, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "22/22 [==============================] - 2s 20ms/step - loss: 0.7497 - accuracy: 0.5029 - val_loss: 0.6946 - val_accuracy: 0.4933\n",
      "Epoch 2/20\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.7078 - accuracy: 0.5243 - val_loss: 0.7106 - val_accuracy: 0.4867\n",
      "Epoch 3/20\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.7158 - accuracy: 0.5214 - val_loss: 0.6879 - val_accuracy: 0.5333\n",
      "Epoch 4/20\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.6958 - accuracy: 0.5357 - val_loss: 0.6930 - val_accuracy: 0.5467\n",
      "Epoch 5/20\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.6841 - accuracy: 0.5786 - val_loss: 0.6957 - val_accuracy: 0.5200\n",
      "Epoch 6/20\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.6902 - accuracy: 0.5529 - val_loss: 0.6802 - val_accuracy: 0.5400\n",
      "Epoch 7/20\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.6831 - accuracy: 0.5657 - val_loss: 0.6896 - val_accuracy: 0.5600\n",
      "Epoch 8/20\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.6805 - accuracy: 0.5657 - val_loss: 0.6898 - val_accuracy: 0.5333\n",
      "Epoch 9/20\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.6719 - accuracy: 0.5900 - val_loss: 0.6936 - val_accuracy: 0.5467\n",
      "Epoch 10/20\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.6700 - accuracy: 0.5943 - val_loss: 0.6847 - val_accuracy: 0.5667\n",
      "Epoch 11/20\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.6730 - accuracy: 0.5829 - val_loss: 0.6835 - val_accuracy: 0.5200\n",
      "Epoch 12/20\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.6530 - accuracy: 0.6114 - val_loss: 0.6987 - val_accuracy: 0.5667\n",
      "Epoch 13/20\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.6493 - accuracy: 0.6029 - val_loss: 0.7006 - val_accuracy: 0.5600\n",
      "Epoch 14/20\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.6337 - accuracy: 0.6371 - val_loss: 0.7079 - val_accuracy: 0.5667\n",
      "Epoch 15/20\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.6276 - accuracy: 0.6757 - val_loss: 0.6982 - val_accuracy: 0.5533\n",
      "Epoch 16/20\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.6191 - accuracy: 0.6586 - val_loss: 0.7360 - val_accuracy: 0.5333\n",
      "Epoch 17/20\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.6125 - accuracy: 0.6629 - val_loss: 0.7190 - val_accuracy: 0.5200\n",
      "Epoch 18/20\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.6010 - accuracy: 0.6700 - val_loss: 0.7438 - val_accuracy: 0.5467\n",
      "Epoch 19/20\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.6094 - accuracy: 0.6757 - val_loss: 0.7016 - val_accuracy: 0.5400\n",
      "Epoch 20/20\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.5921 - accuracy: 0.6857 - val_loss: 0.7262 - val_accuracy: 0.5733\n",
      "Test accuracy: 0.5667\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# Example data loading\n",
    "X = np.random.rand(1000, 20)  # Example data with 1000 samples and 20 features\n",
    "y = np.random.randint(0, 2, 1000)  # Example binary labels (0 or 1) for classification\n",
    "\n",
    "# Split data into training, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# One-hot encoding of labels\n",
    "y_train_onehot = to_categorical(y_train, num_classes=2)\n",
    "y_val_onehot = to_categorical(y_val, num_classes=2)\n",
    "y_test_onehot = to_categorical(y_test, num_classes=2)\n",
    "\n",
    "# Build the model\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "K.clear_session()  # Clear the session before creating a new model\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Input layer\n",
    "model.add(Dense(512, input_dim=X_train.shape[1], activation='relu'))\n",
    "\n",
    "# Add Dropout after the input layer\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Hidden layers\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))  # Dropout after hidden layer\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))  # Dropout after hidden layer\n",
    "\n",
    "# Output layer\n",
    "num_classes = 2  # Change to the number of classes in your task (e.g., 2 for binary classification)\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train_onehot, epochs=20, batch_size=32, validation_data=(X_val, y_val_onehot))\n",
    "\n",
    "# Evaluate the model on test data\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test_onehot, verbose=0)\n",
    "print(f'Test accuracy: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5783 - accuracy: 0.6929 - val_loss: 0.7426 - val_accuracy: 0.5400\n",
      "Epoch 2/20\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.5717 - accuracy: 0.7114 - val_loss: 0.7510 - val_accuracy: 0.5467\n",
      "Epoch 3/20\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.5500 - accuracy: 0.7114 - val_loss: 0.7747 - val_accuracy: 0.5467\n",
      "Epoch 4/20\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.5442 - accuracy: 0.7171 - val_loss: 0.7719 - val_accuracy: 0.5400\n",
      "Epoch 5/20\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.5421 - accuracy: 0.7257 - val_loss: 0.7821 - val_accuracy: 0.5533\n",
      "Epoch 6/20\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.5443 - accuracy: 0.7343 - val_loss: 0.7955 - val_accuracy: 0.6067\n",
      "Epoch 7/20\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.5415 - accuracy: 0.7257 - val_loss: 0.7722 - val_accuracy: 0.5533\n",
      "Epoch 8/20\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4817 - accuracy: 0.7529 - val_loss: 0.8352 - val_accuracy: 0.5600\n",
      "Epoch 9/20\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4970 - accuracy: 0.7571 - val_loss: 0.9318 - val_accuracy: 0.5267\n",
      "Epoch 10/20\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4863 - accuracy: 0.7771 - val_loss: 0.8582 - val_accuracy: 0.5667\n",
      "Epoch 11/20\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.5020 - accuracy: 0.7600 - val_loss: 0.8694 - val_accuracy: 0.5467\n",
      "Epoch 12/20\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4684 - accuracy: 0.7671 - val_loss: 0.8316 - val_accuracy: 0.5800\n",
      "Epoch 13/20\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4771 - accuracy: 0.7714 - val_loss: 0.8233 - val_accuracy: 0.5867\n",
      "Epoch 14/20\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4513 - accuracy: 0.7786 - val_loss: 0.8555 - val_accuracy: 0.5800\n",
      "Epoch 15/20\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4370 - accuracy: 0.8043 - val_loss: 0.9367 - val_accuracy: 0.5467\n",
      "Epoch 16/20\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4267 - accuracy: 0.7971 - val_loss: 0.9331 - val_accuracy: 0.5667\n",
      "Epoch 17/20\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4479 - accuracy: 0.8057 - val_loss: 0.9455 - val_accuracy: 0.5600\n",
      "Epoch 18/20\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4138 - accuracy: 0.8071 - val_loss: 0.9720 - val_accuracy: 0.5533\n",
      "Epoch 19/20\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4297 - accuracy: 0.8143 - val_loss: 0.9247 - val_accuracy: 0.5600\n",
      "Epoch 20/20\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3905 - accuracy: 0.8171 - val_loss: 0.9580 - val_accuracy: 0.5533\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.9357 - accuracy: 0.5467\n",
      "Test Accuracy: 54.67%\n"
     ]
    }
   ],
   "source": [
    "# Retrain the enhanced model\n",
    "history_enhanced = model.fit(X_train, y_train_onehot, epochs=20, batch_size=32, validation_data=(X_val, y_val_onehot))\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test_onehot)\n",
    "print(f\"Test Accuracy: {test_acc * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 - 0s - loss: 0.9357 - accuracy: 0.5467 - 72ms/epoch - 14ms/step\n",
      "Test accuracy before improvements: 54.67%\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'model' is the original model you trained\n",
    "test_loss, test_acc_previous = model.evaluate(X_test, y_test_onehot, verbose=2)\n",
    "print(f\"Test accuracy before improvements: {test_acc_previous * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While accuracy is a good metric, there are many other ways to numerically evaluate a model. Report at least one other metric, and explain what it measures and how it is calculated.\n",
    "\n",
    "Accuracy: 54.67%\n",
    "\n",
    "Other metric: Loss\n",
    "\n",
    "Reason for selection: Loss is another important metric because it provides more information about the model’s performance than accuracy alone. While accuracy only measures the percentage of correct predictions, loss measures the overall error of the model’s predictions by calculating the difference between the predicted values and the true values. Lower loss indicates better performance of the model.\n",
    "\n",
    "Value of metric: The final loss after training was approximately 0.9357.\n",
    "\n",
    "Interpretation of metric value: A loss value of 0.9357 means that the model is making some significant errors in predicting the class labels, but it is not extremely high, suggesting that there is room for improvement. The goal is to minimize the loss as much as possible to improve the accuracy and generalization of the model.\n",
    "\n",
    "\n",
    "\n",
    "Task 3c: Visualize the model's learning\n",
    "\n",
    "In this task, you should plot the training accuracy and validation accuracy with respect to epochs. The plots will show how the model's performance improves (or does not improve) as training progresses. If the validation accuracy is lower than the training accuracy, it might indicate overfitting, where the model performs well on the training set but not on unseen data.\n",
    "\n",
    "Regarding the images:\n",
    "\n",
    "Select one image the model correctly classified from the test set.\n",
    "\n",
    "Select one image the model incorrectly classified from the test set.\n",
    "\n",
    "Plot the images and report the classification probabilities for each.\n",
    "\n",
    "\n",
    "Discuss what these plots indicate:\n",
    "\n",
    "The training accuracy is typically expected to increase over time as the model learns from the data.\n",
    "\n",
    "The validation accuracy might fluctuate or plateau, and if it decreases after a certain point, this could indicate overfitting.\n",
    "\n",
    "The classification probabilities show the model’s confidence in its predictions for each image. A higher probability means the model is more confident in its classification.\n",
    "\n",
    "\n",
    "Task 4: Model Enhancement (Complete or Incomplete)\n",
    "\n",
    "Task 4a: Implementation of at least one advanced technique\n",
    "\n",
    "In this task, I chose to implement early stopping as the advanced technique to improve the model. Early stopping helps prevent overfitting by stopping training when the validation loss stops improving, ensuring the model does not continue to fit noise in the training data.\n",
    "\n",
    "I selected this technique because it can help to stop the training at the optimal point, saving time and improving generalization to the test data. Additionally, it avoids overfitting the model to the training data.\n",
    "\n",
    "I tuned the patience hyperparameter to 5, meaning the model will stop training if the validation loss does not improve for 5 consecutive epochs.\n",
    "\n",
    "\n",
    "Task 4b: Evaluation of the enhanced model\n",
    "\n",
    "I re-trained the model using the same number of epochs as before (20 epochs). The model's performance, measured by accuracy and loss, was compared to the results from before the enhancements. The evaluation showed that although the model did not show significant improvement in accuracy, early stopping helped to avoid unnecessary training and prevent potential overfitting.\n",
    "\n",
    "\n",
    "Task 4c: Discussion of the results\n",
    "\n",
    "The model’s performance did not improve significantly after the enhancement. The test accuracy remained at 54.67%. This lack of improvement might be due to factors like insufficient model complexity, suboptimal training duration, or limited data. While the technique (early stopping) prevents overfitting and helps save training time, it did not lead to a major performance boost in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is still room for improvement. Using a more complex model architecture, such as deeper neural networks or using pre-trained models, might help the model better capture the underlying patterns in the data. Additionally, techniques like data augmentation and better feature engineering could lead to better results.\n",
    "\n",
    "Future experiments could explore hyperparameter optimization, more advanced regularization techniques, or different optimizers to further enhance model performance.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsi_participant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
